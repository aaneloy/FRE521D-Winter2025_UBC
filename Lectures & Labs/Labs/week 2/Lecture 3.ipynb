{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618eb7f0-fcab-45fd-b94b-771c62e7dac1",
   "metadata": {},
   "source": [
    "# **Lecture 3: Machine Learning Modeling**\n",
    "\n",
    "## **Learning Outcomes**\n",
    "By the end of this lecture, students will be able to:\n",
    "- Understand and implement basic machine learning models for regression and classification tasks.\n",
    "- Prepare datasets for machine learning, including train-test splitting and feature scaling.\n",
    "- Evaluate the performance of machine learning models using appropriate metrics.\n",
    "- Compare different machine learning algorithms and interpret their results.\n",
    "\n",
    "---\n",
    "\n",
    "## **Objectives**\n",
    "- Introduce regression and classification concepts in machine learning.\n",
    "- Demonstrate regression modeling to predict continuous values, such as `Nutrition Density`.\n",
    "- Implement classification modeling to predict categorical values, such as `Food_Group_LabelEncoded`.\n",
    "- Provide insights into feature importance and performance evaluation techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## **What We Will Do in This Notebook**\n",
    "1. **Dataset Preparation**:\n",
    "   - Load the dataset (`final_nutrition_data.csv`).\n",
    "   - Perform train-test split.\n",
    "   - Scale the features using `StandardScaler`.\n",
    "\n",
    "2. **Regression Task**:\n",
    "   - Define regression targets and features.\n",
    "   - Train and evaluate **Linear Regression** and **Random Forest Regressor** models.\n",
    "   - Compare models using metrics like MAE, MSE, and \\(R^2\\).\n",
    "   - Visualize regression predictions.\n",
    "\n",
    "3. **Classification Task**:\n",
    "   - Define classification targets and features.\n",
    "   - Train and evaluate **Logistic Regression** and **Random Forest Classifier** models.\n",
    "   - Use classification metrics such as precision, recall, and F1-score.\n",
    "   - Visualize classification results, including confusion matrix and feature importance.\n",
    "\n",
    "4. **Insights and Summary**:\n",
    "   - Interpret model results and key takeaways from both tasks.\n",
    "   - Discuss potential improvements and further applications.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feacb5ca-1c82-409d-95cf-28b7fe8bd151",
   "metadata": {},
   "source": [
    "## **Step 1: Dataset Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fabb37-afea-4f9e-9c82-932b81b8d913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Caloric Value       Fat  Saturated Fats  Monounsaturated Fats  \\\n",
      "0       1.068000  3.054126        4.273590              1.743794   \n",
      "1      -0.793001 -0.295498        0.251201             -0.460053   \n",
      "2      -1.006007 -0.571100       -0.169747             -0.625342   \n",
      "3      -1.129326 -1.016303       -0.777782             -0.905781   \n",
      "4      -0.243669  0.573708        1.326956              0.146005   \n",
      "\n",
      "   Polyunsaturated Fats  Carbohydrates    Sugars   Protein  Dietary Fiber  \\\n",
      "0             -0.173496      -0.473409  2.087806 -0.205790      -0.481632   \n",
      "1             -0.883996      -0.657250  2.756392 -0.992850      -0.350809   \n",
      "2             -0.846695      -0.632181  0.368585 -0.947875      -0.481632   \n",
      "3             -0.817387      -0.615468  0.464097 -0.767976      -0.481632   \n",
      "4             -0.617559      -0.699032 -0.491026 -0.329471      -0.481632   \n",
      "\n",
      "   Cholesterol  ...    Copper      Iron  Magnesium  Manganese  Phosphorus  \\\n",
      "0     1.116587  ... -0.631792 -0.962709  -0.572509  -0.436944   -0.055764   \n",
      "1    -1.001910  ... -0.938118 -1.077764  -1.055642  -0.840155   -1.166761   \n",
      "2    -0.729099  ... -0.289427 -1.068559  -0.987435  -0.391125   -0.950813   \n",
      "3    -0.927813  ... -0.586744 -1.016785  -0.828285  -0.711861   -0.275501   \n",
      "4    -0.217157  ... -0.703869 -1.050151  -0.583877  -0.556075    0.192388   \n",
      "\n",
      "   Potassium  Selenium      Zinc  Nutrition Density  Food_Group_LabelEncoded  \n",
      "0  -0.330419  0.313679 -0.018519           0.826281                 0.237607  \n",
      "1  -1.019963 -1.461763 -1.075020          -0.960414                 0.724952  \n",
      "2  -0.821959 -0.343892 -0.995028          -0.650830                -0.670900  \n",
      "3  -0.753111 -1.034342 -0.622234          -0.068084                -0.676917  \n",
      "4  -0.923896 -0.442528  0.585195           2.363612                 1.236363  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "### Load the Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"final_nutrition_data.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d7ab1cc-323a-4340-ba05-18d867203710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns as a list: ['Caloric Value', 'Fat', 'Saturated Fats', 'Monounsaturated Fats', 'Polyunsaturated Fats', 'Carbohydrates', 'Sugars', 'Protein', 'Dietary Fiber', 'Cholesterol', 'Sodium', 'Water', 'Vitamin A', 'Vitamin B1', 'Vitamin B11', 'Vitamin B12', 'Vitamin B2', 'Vitamin B3', 'Vitamin B5', 'Vitamin B6', 'Vitamin C', 'Vitamin D', 'Vitamin E', 'Vitamin K', 'Calcium', 'Copper', 'Iron', 'Magnesium', 'Manganese', 'Phosphorus', 'Potassium', 'Selenium', 'Zinc', 'Nutrition Density', 'Food_Group_LabelEncoded']\n"
     ]
    }
   ],
   "source": [
    "# Get column names as a list\n",
    "columns = df.columns.tolist()\n",
    "print(\"Columns as a list:\", columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d2f965-9bd1-4574-aaf8-09ea96f10f41",
   "metadata": {},
   "source": [
    "### **What Questions Can We Ask for Regression?**\n",
    "Regression modeling helps answer questions about **continuous numeric targets** based on independent features. Examples include:\n",
    "- **Caloric Value Prediction**: \n",
    "  - Can we predict the `Caloric Value` of food items based on features like `Fat`, `Protein`, and `Carbohydrates`? \n",
    "- **Nutrition Density Analysis**:\n",
    "  - How well do features like `Fat`, `Sugars`, and `Dietary Fiber` explain variations in `Nutrition Density`?  \n",
    "- **Micronutrient Contribution**:\n",
    "  - What is the contribution of vitamins and minerals (e.g., `Vitamin A`, `Calcium`) to changes in `Cholesterol` levels?\n",
    "\n",
    "---\n",
    "\n",
    "## **Next Steps**\n",
    "### 1. Define the Problem\n",
    "- **Target Variable**: Identify the column to predict (e.g., `Caloric Value`).\n",
    "- **Features (Predictors)**: Select independent variables that contribute to the prediction.\n",
    "\n",
    "### 2. Prepare Data\n",
    "- Perform a train-test split to ensure proper evaluation of the model.\n",
    "- Standardize or normalize features if necessary.\n",
    "\n",
    "### 3. Build Regression Models\n",
    "- Use models like:\n",
    "  - Linear Regression\n",
    "  - Decision Tree Regressor\n",
    "  - Random Forest Regressor\n",
    "\n",
    "### 4. Evaluate Performance\n",
    "- Metrics to evaluate the regression models:\n",
    "  - **Mean Absolute Error (MAE)**\n",
    "  - **Mean Squared Error (MSE)**\n",
    "  - **R-squared (R²)**\n",
    "\n",
    "### 5. Extend the Analysis\n",
    "- Explore feature importance to understand the key drivers of predictions.\n",
    "- Experiment with advanced models like Gradient Boosting or Neural Networks for improved results.\n",
    "- Use hyperparameter tuning for optimization.\n",
    "\n",
    "---\n",
    "\n",
    "### Let’s move forward and start coding the regression process!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18959597-16fd-4610-ba0d-f132ad60bde8",
   "metadata": {},
   "source": [
    "## Step 1: Train a Regression Model with All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667e28c7-c917-4c29-babe-44c58a4d3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define features and target\n",
    "X_all = df[['Caloric Value', 'Fat', 'Saturated Fats', 'Monounsaturated Fats', 'Polyunsaturated Fats', 'Carbohydrates', 'Sugars', 'Protein', \n",
    "            'Dietary Fiber', 'Sodium', 'Water', 'Vitamin A', 'Vitamin B1', 'Vitamin B11', 'Vitamin B12', 'Vitamin B2', \n",
    "            'Vitamin B3', 'Vitamin B5', 'Vitamin B6', 'Vitamin C', 'Vitamin D', 'Vitamin E', 'Vitamin K', 'Calcium', 'Copper', 'Iron', \n",
    "            'Magnesium', 'Manganese', 'Phosphorus', 'Potassium', 'Selenium', 'Zinc', 'Nutrition Density', 'Food_Group_LabelEncoded']]\n",
    "y_all = df['Cholesterol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d725764-4cc1-4127-a67c-f2388cc134f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caloric Value</th>\n",
       "      <th>Fat</th>\n",
       "      <th>Saturated Fats</th>\n",
       "      <th>Monounsaturated Fats</th>\n",
       "      <th>Polyunsaturated Fats</th>\n",
       "      <th>Carbohydrates</th>\n",
       "      <th>Sugars</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Dietary Fiber</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>...</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Iron</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Manganese</th>\n",
       "      <th>Phosphorus</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Selenium</th>\n",
       "      <th>Zinc</th>\n",
       "      <th>Nutrition Density</th>\n",
       "      <th>Food_Group_LabelEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.068000</td>\n",
       "      <td>3.054126</td>\n",
       "      <td>4.273590</td>\n",
       "      <td>1.743794</td>\n",
       "      <td>-0.173496</td>\n",
       "      <td>-0.473409</td>\n",
       "      <td>2.087806</td>\n",
       "      <td>-0.205790</td>\n",
       "      <td>-0.481632</td>\n",
       "      <td>-0.182895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.631792</td>\n",
       "      <td>-0.962709</td>\n",
       "      <td>-0.572509</td>\n",
       "      <td>-0.436944</td>\n",
       "      <td>-0.055764</td>\n",
       "      <td>-0.330419</td>\n",
       "      <td>0.313679</td>\n",
       "      <td>-0.018519</td>\n",
       "      <td>0.826281</td>\n",
       "      <td>0.237607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.793001</td>\n",
       "      <td>-0.295498</td>\n",
       "      <td>0.251201</td>\n",
       "      <td>-0.460053</td>\n",
       "      <td>-0.883996</td>\n",
       "      <td>-0.657250</td>\n",
       "      <td>2.756392</td>\n",
       "      <td>-0.992850</td>\n",
       "      <td>-0.350809</td>\n",
       "      <td>-0.845990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.938118</td>\n",
       "      <td>-1.077764</td>\n",
       "      <td>-1.055642</td>\n",
       "      <td>-0.840155</td>\n",
       "      <td>-1.166761</td>\n",
       "      <td>-1.019963</td>\n",
       "      <td>-1.461763</td>\n",
       "      <td>-1.075020</td>\n",
       "      <td>-0.960414</td>\n",
       "      <td>0.724952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.006007</td>\n",
       "      <td>-0.571100</td>\n",
       "      <td>-0.169747</td>\n",
       "      <td>-0.625342</td>\n",
       "      <td>-0.846695</td>\n",
       "      <td>-0.632181</td>\n",
       "      <td>0.368585</td>\n",
       "      <td>-0.947875</td>\n",
       "      <td>-0.481632</td>\n",
       "      <td>-0.744316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289427</td>\n",
       "      <td>-1.068559</td>\n",
       "      <td>-0.987435</td>\n",
       "      <td>-0.391125</td>\n",
       "      <td>-0.950813</td>\n",
       "      <td>-0.821959</td>\n",
       "      <td>-0.343892</td>\n",
       "      <td>-0.995028</td>\n",
       "      <td>-0.650830</td>\n",
       "      <td>-0.670900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.129326</td>\n",
       "      <td>-1.016303</td>\n",
       "      <td>-0.777782</td>\n",
       "      <td>-0.905781</td>\n",
       "      <td>-0.817387</td>\n",
       "      <td>-0.615468</td>\n",
       "      <td>0.464097</td>\n",
       "      <td>-0.767976</td>\n",
       "      <td>-0.481632</td>\n",
       "      <td>-0.624959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.586744</td>\n",
       "      <td>-1.016785</td>\n",
       "      <td>-0.828285</td>\n",
       "      <td>-0.711861</td>\n",
       "      <td>-0.275501</td>\n",
       "      <td>-0.753111</td>\n",
       "      <td>-1.034342</td>\n",
       "      <td>-0.622234</td>\n",
       "      <td>-0.068084</td>\n",
       "      <td>-0.676917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.243669</td>\n",
       "      <td>0.573708</td>\n",
       "      <td>1.326956</td>\n",
       "      <td>0.146005</td>\n",
       "      <td>-0.617559</td>\n",
       "      <td>-0.699032</td>\n",
       "      <td>-0.491026</td>\n",
       "      <td>-0.329471</td>\n",
       "      <td>-0.481632</td>\n",
       "      <td>-0.720002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.703869</td>\n",
       "      <td>-1.050151</td>\n",
       "      <td>-0.583877</td>\n",
       "      <td>-0.556075</td>\n",
       "      <td>0.192388</td>\n",
       "      <td>-0.923896</td>\n",
       "      <td>-0.442528</td>\n",
       "      <td>0.585195</td>\n",
       "      <td>2.363612</td>\n",
       "      <td>1.236363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-0.905109</td>\n",
       "      <td>-1.037503</td>\n",
       "      <td>-0.779653</td>\n",
       "      <td>-0.919004</td>\n",
       "      <td>-0.879556</td>\n",
       "      <td>-0.548617</td>\n",
       "      <td>-0.491026</td>\n",
       "      <td>-0.329471</td>\n",
       "      <td>-0.481632</td>\n",
       "      <td>-0.684637</td>\n",
       "      <td>...</td>\n",
       "      <td>1.764761</td>\n",
       "      <td>0.533002</td>\n",
       "      <td>0.325550</td>\n",
       "      <td>-0.381961</td>\n",
       "      <td>-0.788852</td>\n",
       "      <td>-0.495867</td>\n",
       "      <td>-1.100099</td>\n",
       "      <td>-0.320377</td>\n",
       "      <td>-0.641216</td>\n",
       "      <td>1.531177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.843783</td>\n",
       "      <td>-0.592300</td>\n",
       "      <td>-0.637466</td>\n",
       "      <td>-0.790630</td>\n",
       "      <td>-0.528746</td>\n",
       "      <td>-0.055590</td>\n",
       "      <td>-0.491026</td>\n",
       "      <td>2.661355</td>\n",
       "      <td>-0.481632</td>\n",
       "      <td>2.248456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037159</td>\n",
       "      <td>3.179259</td>\n",
       "      <td>1.394127</td>\n",
       "      <td>0.076234</td>\n",
       "      <td>3.090643</td>\n",
       "      <td>-0.462777</td>\n",
       "      <td>-0.113742</td>\n",
       "      <td>0.736124</td>\n",
       "      <td>0.910816</td>\n",
       "      <td>-0.791232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-0.658471</td>\n",
       "      <td>-0.422699</td>\n",
       "      <td>-0.450379</td>\n",
       "      <td>-0.294765</td>\n",
       "      <td>-0.173496</td>\n",
       "      <td>-0.172579</td>\n",
       "      <td>-0.491026</td>\n",
       "      <td>-0.846682</td>\n",
       "      <td>-0.481632</td>\n",
       "      <td>-0.624959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037159</td>\n",
       "      <td>-0.272381</td>\n",
       "      <td>-0.833969</td>\n",
       "      <td>-0.771426</td>\n",
       "      <td>-0.857046</td>\n",
       "      <td>-0.857717</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>2.849125</td>\n",
       "      <td>-0.781873</td>\n",
       "      <td>0.345906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-0.793001</td>\n",
       "      <td>-0.804302</td>\n",
       "      <td>-0.684238</td>\n",
       "      <td>-0.570246</td>\n",
       "      <td>-0.795184</td>\n",
       "      <td>-0.732457</td>\n",
       "      <td>-0.491026</td>\n",
       "      <td>-0.093353</td>\n",
       "      <td>-0.481632</td>\n",
       "      <td>-0.403927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397542</td>\n",
       "      <td>-0.732600</td>\n",
       "      <td>-0.299681</td>\n",
       "      <td>-0.647714</td>\n",
       "      <td>-0.413783</td>\n",
       "      <td>-0.447300</td>\n",
       "      <td>1.069886</td>\n",
       "      <td>-0.773163</td>\n",
       "      <td>-0.820358</td>\n",
       "      <td>1.188230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-0.781790</td>\n",
       "      <td>-0.337898</td>\n",
       "      <td>-0.590694</td>\n",
       "      <td>-0.074380</td>\n",
       "      <td>-0.351121</td>\n",
       "      <td>-0.732457</td>\n",
       "      <td>-0.491026</td>\n",
       "      <td>-0.565589</td>\n",
       "      <td>-0.481632</td>\n",
       "      <td>-0.624959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.802974</td>\n",
       "      <td>-0.962709</td>\n",
       "      <td>-0.782814</td>\n",
       "      <td>-0.624804</td>\n",
       "      <td>-0.764226</td>\n",
       "      <td>-0.577523</td>\n",
       "      <td>0.182165</td>\n",
       "      <td>-0.960314</td>\n",
       "      <td>-0.814613</td>\n",
       "      <td>-0.815298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Caloric Value       Fat  Saturated Fats  Monounsaturated Fats  \\\n",
       "0         1.068000  3.054126        4.273590              1.743794   \n",
       "1        -0.793001 -0.295498        0.251201             -0.460053   \n",
       "2        -1.006007 -0.571100       -0.169747             -0.625342   \n",
       "3        -1.129326 -1.016303       -0.777782             -0.905781   \n",
       "4        -0.243669  0.573708        1.326956              0.146005   \n",
       "..             ...       ...             ...                   ...   \n",
       "180      -0.905109 -1.037503       -0.779653             -0.919004   \n",
       "181       0.843783 -0.592300       -0.637466             -0.790630   \n",
       "182      -0.658471 -0.422699       -0.450379             -0.294765   \n",
       "183      -0.793001 -0.804302       -0.684238             -0.570246   \n",
       "184      -0.781790 -0.337898       -0.590694             -0.074380   \n",
       "\n",
       "     Polyunsaturated Fats  Carbohydrates    Sugars   Protein  Dietary Fiber  \\\n",
       "0               -0.173496      -0.473409  2.087806 -0.205790      -0.481632   \n",
       "1               -0.883996      -0.657250  2.756392 -0.992850      -0.350809   \n",
       "2               -0.846695      -0.632181  0.368585 -0.947875      -0.481632   \n",
       "3               -0.817387      -0.615468  0.464097 -0.767976      -0.481632   \n",
       "4               -0.617559      -0.699032 -0.491026 -0.329471      -0.481632   \n",
       "..                    ...            ...       ...       ...            ...   \n",
       "180             -0.879556      -0.548617 -0.491026 -0.329471      -0.481632   \n",
       "181             -0.528746      -0.055590 -0.491026  2.661355      -0.481632   \n",
       "182             -0.173496      -0.172579 -0.491026 -0.846682      -0.481632   \n",
       "183             -0.795184      -0.732457 -0.491026 -0.093353      -0.481632   \n",
       "184             -0.351121      -0.732457 -0.491026 -0.565589      -0.481632   \n",
       "\n",
       "       Sodium  ...    Copper      Iron  Magnesium  Manganese  Phosphorus  \\\n",
       "0   -0.182895  ... -0.631792 -0.962709  -0.572509  -0.436944   -0.055764   \n",
       "1   -0.845990  ... -0.938118 -1.077764  -1.055642  -0.840155   -1.166761   \n",
       "2   -0.744316  ... -0.289427 -1.068559  -0.987435  -0.391125   -0.950813   \n",
       "3   -0.624959  ... -0.586744 -1.016785  -0.828285  -0.711861   -0.275501   \n",
       "4   -0.720002  ... -0.703869 -1.050151  -0.583877  -0.556075    0.192388   \n",
       "..        ...  ...       ...       ...        ...        ...         ...   \n",
       "180 -0.684637  ...  1.764761  0.533002   0.325550  -0.381961   -0.788852   \n",
       "181  2.248456  ... -0.037159  3.179259   1.394127   0.076234    3.090643   \n",
       "182 -0.624959  ... -0.037159 -0.272381  -0.833969  -0.771426   -0.857046   \n",
       "183 -0.403927  ... -0.397542 -0.732600  -0.299681  -0.647714   -0.413783   \n",
       "184 -0.624959  ... -0.802974 -0.962709  -0.782814  -0.624804   -0.764226   \n",
       "\n",
       "     Potassium  Selenium      Zinc  Nutrition Density  Food_Group_LabelEncoded  \n",
       "0    -0.330419  0.313679 -0.018519           0.826281                 0.237607  \n",
       "1    -1.019963 -1.461763 -1.075020          -0.960414                 0.724952  \n",
       "2    -0.821959 -0.343892 -0.995028          -0.650830                -0.670900  \n",
       "3    -0.753111 -1.034342 -0.622234          -0.068084                -0.676917  \n",
       "4    -0.923896 -0.442528  0.585195           2.363612                 1.236363  \n",
       "..         ...       ...       ...                ...                      ...  \n",
       "180  -0.495867 -1.100099 -0.320377          -0.641216                 1.531177  \n",
       "181  -0.462777 -0.113742  0.736124           0.910816                -0.791232  \n",
       "182  -0.857717  0.971250  2.849125          -0.781873                 0.345906  \n",
       "183  -0.447300  1.069886 -0.773163          -0.820358                 1.188230  \n",
       "184  -0.577523  0.182165 -0.960314          -0.814613                -0.815298  \n",
       "\n",
       "[185 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb2b778-de23-42ba-a586-e5f4b4399f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.116587\n",
       "1     -1.001910\n",
       "2     -0.729099\n",
       "3     -0.927813\n",
       "4     -0.217157\n",
       "         ...   \n",
       "180   -0.382191\n",
       "181    1.291725\n",
       "182   -0.392295\n",
       "183   -0.240733\n",
       "184   -0.695418\n",
       "Name: Cholesterol, Length: 185, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57bb46e1-3837-45b5-82f0-0f4aae4312cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b4d43cb-5904-4470-949b-e182e7f8f869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a linear regression model\n",
    "model_all = LinearRegression()\n",
    "model_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5237ea7b-8337-4a09-9b28-d28cbf82331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred_all = model_all.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfca8cad-c023-42d8-aa35-c423cbfdb710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Actual  Predicted\n",
      "19  -0.523648  -0.178671\n",
      "42   0.372250   1.743655\n",
      "156 -0.301358   0.381486\n",
      "111 -0.429343   0.034472\n",
      "148 -0.429343  -0.338209\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to display actual and predicted values\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_all\n",
    "})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(comparison_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "651bd004-5f9c-4210-a598-a1415717199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mae_all = mean_absolute_error(y_test, y_pred_all)\n",
    "mse_all = mean_squared_error(y_test, y_pred_all)\n",
    "r2_all = r2_score(y_test, y_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb7e2e4d-259e-4f19-a341-3619c78fbc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with All Features:\n",
      "Mean Absolute Error (MAE): 0.5426082940843728\n",
      "Mean Squared Error (MSE): 0.4635843328926965\n",
      "R-squared (R²): 0.2896595494077906\n"
     ]
    }
   ],
   "source": [
    "print(f\"Performance with All Features:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_all}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_all}\")\n",
    "print(f\"R-squared (R²): {r2_all}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e268056-88af-43b9-a042-384f809f6ec5",
   "metadata": {},
   "source": [
    "**Performance Metrics:**\n",
    "1. **Mean Absolute Error (MAE):** \n",
    "   - The MAE of `0.5426` indicates that, on average, the predicted values are off by approximately `0.533` units from the actual values.\n",
    "   - MAE provides an intuitive measure of prediction error in the same units as the target variable (`Caloric Value`).\n",
    "\n",
    "2. **Mean Squared Error (MSE):**\n",
    "   - The MSE of `0.4635` reflects the average squared difference between the predicted and actual values.\n",
    "   - MSE penalizes larger errors more heavily than smaller ones, making it sensitive to outliers. \n",
    "\n",
    "3. **R-squared (R²):**\n",
    "   - The R² value of `0.2896` means that the model explains about `28.16%` of the variance in the target variable (`Caloric Value`) using all the provided features.\n",
    "   - This relatively low R² suggests that many features in the dataset do not strongly contribute to predicting `Caloric Value` or that the relationship between the features and the target variable is weak or nonlinear.\n",
    "\n",
    "---\n",
    "\n",
    "### **Insights**\n",
    "1. **Model Fit:**\n",
    "   - The low R² value indicates that the model may not be fitting the data well, potentially due to:\n",
    "     - Irrelevant or weakly correlated features.\n",
    "     - A nonlinear relationship that is not captured effectively by the linear regression model.\n",
    "\n",
    "2. **Error Analysis:**\n",
    "   - The MAE and MSE values suggest room for improvement in prediction accuracy. High error metrics relative to the data's range indicate the need for better feature selection or alternative modeling techniques.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "1. **Feature Selection:**\n",
    "   - Use techniques like Recursive Feature Elimination (RFE) to identify the most predictive features and exclude irrelevant ones.\n",
    "   \n",
    "2. **Nonlinear Models:**\n",
    "   - Explore nonlinear models like decision trees, random forests, or gradient boosting to capture complex relationships in the data.\n",
    "\n",
    "3. **Feature Engineering:**\n",
    "   - Consider transforming features or creating interaction terms that might better explain the variability in `Caloric Value`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaeb46b-ef73-446a-84bc-f915a161ddef",
   "metadata": {},
   "source": [
    "## Using Machine Learning for Feature Selection\n",
    "To improve the model's performance, we will use machine learning techniques such as feature importance ranking with tree-based methods or recursive feature elimination (RFE) to select relevant features. Below is the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4942718-5799-411b-b313-57c1256a9088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features by RFE: Index(['Caloric Value', 'Fat', 'Saturated Fats', 'Carbohydrates', 'Protein',\n",
      "       'Vitamin C', 'Calcium', 'Iron', 'Potassium', 'Nutrition Density'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Initialize the regressor\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Apply Recursive Feature Elimination\n",
    "rfe = RFE(estimator=regressor, n_features_to_select=10)  # Select top 10 features\n",
    "rfe.fit(X_all, y_all)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features_rfe = X_all.columns[rfe.support_]\n",
    "print(f\"Selected Features by RFE: {selected_features_rfe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79cac78-d675-4163-b89b-23052526cb07",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "RFE recursively eliminates the least important features based on model performance.\n",
    "Here, we use RFE to select the top 10 features contributing to predicting Cholesterol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9e6efc4-f18d-43bd-8818-dc25a2f5062f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with Selected Features:\n",
      "Mean Absolute Error (MAE): 0.40627593402503137\n",
      "Mean Squared Error (MSE): 0.32970142014895376\n",
      "R-squared (R²): 0.49480549981461885\n"
     ]
    }
   ],
   "source": [
    "# Use selected features from RFE\n",
    "X_selected = df[selected_features_rfe]\n",
    "\n",
    "# Train-test split with selected features\n",
    "X_train_selected, X_test_selected, y_train_selected, y_test_selected = train_test_split(X_selected, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a new linear regression model\n",
    "model_selected = LinearRegression()\n",
    "model_selected.fit(X_train_selected, y_train_selected)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_selected = model_selected.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_selected = mean_absolute_error(y_test_selected, y_pred_selected)\n",
    "mse_selected = mean_squared_error(y_test_selected, y_pred_selected)\n",
    "r2_selected = r2_score(y_test_selected, y_pred_selected)\n",
    "\n",
    "print(f\"Performance with Selected Features:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_selected}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_selected}\")\n",
    "print(f\"R-squared (R²): {r2_selected}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6003b-30cd-4fde-b5eb-81c5018f553a",
   "metadata": {},
   "source": [
    "Let's apply a Random Forest Regressor, a nonlinear model that can capture complex interactions between features and improve the accuracy of predictions. We'll also evaluate its performance using the same metrics: MAE, MSE, and R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b31cab-06a4-44b0-8c05-80f35fcee6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with Random Forest Regressor:\n",
      "Mean Absolute Error (MAE): 0.4419504744129756\n",
      "Mean Squared Error (MSE): 0.3933250530775419\n",
      "R-squared (R²): 0.39731635517334063\n",
      "       Actual  Predicted\n",
      "19  -0.523648  -0.221333\n",
      "42   0.372250   2.110664\n",
      "156 -0.301358  -0.360366\n",
      "111 -0.429343  -0.184689\n",
      "148 -0.429343  -0.616977\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Display results\n",
    "print(\"Performance with Random Forest Regressor:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_rf}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf}\")\n",
    "print(f\"R-squared (R²): {r2_rf}\")\n",
    "\n",
    "# Create a DataFrame to show actual vs predicted values\n",
    "actual_vs_pred_rf = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_rf\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(actual_vs_pred_rf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6ff7856-0a2a-40de-bcb4-43ffd2a837d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with Random Forest Regressor with RFE:\n",
      "Mean Absolute Error (MAE): 0.40627593402503137\n",
      "Mean Squared Error (MSE): 0.32970142014895376\n",
      "R-squared (R²): 0.49480549981461885\n",
      "       Actual  Predicted\n",
      "19  -0.523648  -0.011976\n",
      "42   0.372250   2.507015\n",
      "156 -0.301358  -0.561572\n",
      "111 -0.429343   0.195395\n",
      "148 -0.429343  -0.455580\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf_model.fit(X_train_selected, y_train_selected)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate performance\n",
    "mae_rf = mean_absolute_error(y_test_selected, y_pred_selected)\n",
    "mse_rf = mean_squared_error(y_test_selected, y_pred_selected)\n",
    "r2_rf = r2_score(y_test_selected, y_pred_selected)\n",
    "\n",
    "# Display results\n",
    "print(\"Performance with Random Forest Regressor with RFE:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_rf}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf}\")\n",
    "print(f\"R-squared (R²): {r2_rf}\")\n",
    "\n",
    "# Create a DataFrame to show actual vs predicted values\n",
    "actual_vs_pred_rf = pd.DataFrame({\n",
    "    'Actual': y_test_selected,\n",
    "    'Predicted': y_pred_rf\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(actual_vs_pred_rf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973a406-1b22-4675-853e-72494705e43a",
   "metadata": {},
   "source": [
    "# Next Steps to Improve Accuracy\n",
    "\n",
    "While the Random Forest Regressor with RFE-selected features has shown an improvement in performance metrics, there are still steps we can take to further refine the model and improve accuracy. Below are some strategies:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Hyperparameter Tuning\n",
    "- Use techniques like Grid Search or Randomized Search to optimize the hyperparameters of the Random Forest Regressor, such as:\n",
    "  - `n_estimators`: Number of trees in the forest.\n",
    "  - `max_depth`: Maximum depth of the trees.\n",
    "  - `min_samples_split`: Minimum number of samples required to split a node.\n",
    "  - `min_samples_leaf`: Minimum number of samples required to be a leaf node.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Feature Engineering\n",
    "- **Interaction Features**: Create new features by combining existing ones, e.g., `Fat * Protein` or `Sugars / Carbohydrates`.\n",
    "- **Polynomial Features**: Add non-linear combinations of the features using polynomial transformations.\n",
    "- **Log Transformations**: Apply log transformations to skewed numerical features to normalize their distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Model Complexity\n",
    "- **Boosting Algorithms**:\n",
    "  - Try Gradient Boosting Machines (GBM), XGBoost, or CatBoost. These models are often more effective for non-linear relationships.\n",
    "- **Ensemble Models**:\n",
    "  - Combine predictions from multiple models using techniques like stacking or blending.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Cross-Validation\n",
    "- Use k-fold cross-validation to ensure the model's performance is robust and not overfitted to a particular train-test split.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Dimensionality Reduction\n",
    "- Use methods like Principal Component Analysis (PCA) or feature selection based on importance scores to reduce noise and focus on the most impactful features.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Outlier Handling\n",
    "- Analyze residuals (differences between actual and predicted values) to identify and handle outliers that might be influencing the model.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Fine-Tuning Data Preprocessing\n",
    "- Standardize or normalize numerical features to ensure all variables are on the same scale.\n",
    "- Check for multicollinearity between features and drop highly correlated ones if necessary.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Neural Networks\n",
    "- For complex relationships, try using a basic feed-forward neural network. Neural networks can capture intricate patterns that traditional ML models may miss.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Model Interpretation\n",
    "- Use SHAP (SHapley Additive exPlanations) or feature importance plots to interpret which features contribute most to the predictions. Adjust feature selection or engineering accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Experiment with Other Targets\n",
    "- Test whether related variables (e.g., `Nutrition Density` or `Protein`) can also serve as prediction targets to uncover additional insights.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ced504-de00-4dee-856b-d2888b94aba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
